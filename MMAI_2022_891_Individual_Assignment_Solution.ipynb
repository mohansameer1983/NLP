{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohansameer1983/NLP/blob/main/MMAI_2022_891_Individual_Assignment_Solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKmorPdno_n_"
      },
      "source": [
        "# MMAI 891: Individual Assignment\n",
        "\n",
        "Version 1: Updated February 9, 2022\n",
        "\n",
        "<font color='red'>\\# TODO: fill in the below</font>\n",
        "\n",
        "- [Sameer, Mohan]\n",
        "- [20309780]\n",
        "- [Section 1]\n",
        "- [Greenlight]\n",
        "- [22-04-2022]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emfFtv4aHBI1"
      },
      "source": [
        "# Assignment Instructions\n",
        "\n",
        "This assignment contains one (1) question with multiple parts and one (1) optional question for bonus marks. The questions and parts are wholly contained in this Google Colab Notebook. \n",
        "\n",
        "You are to make a copy of this Notebook and edit the copy to provide your answers/solutions. You are to complete the assignment entirely within Google Colab. Why?\n",
        "\n",
        "- It gives you practice using cloud-based interactive notebook environments (which is a popular workflow)\n",
        "- It is easier for you to manage the environment (e.g., installing packages, etc.)\n",
        "- Google Colab has nice, beefy machines, so you don't have to worry about running out of memory on your local computer.\n",
        "- It will be easier for the TA to help you debug your code if you need help\n",
        "- It will be easier for the TA to mark/run your code\n",
        "\n",
        "## Questions\n",
        "\n",
        "Each question has multiple tasks. There are two possible types of tasks: tasks that require you to write code and tasks that require you to write text responses. A grading rubric is provided on D2L for each question.\n",
        "\n",
        "For tasks that require **code**:\n",
        "- Use Python to complete the task.\n",
        "- You may use standard Python libraries, including scikit-learn, pandas, and numpy.\n",
        "- Tips:\n",
        "  - Submit code that runs without errors.\n",
        "  - Submit code that is reproducible. E.g., set random number seeds as appropriate. You should be able to run your code again and again and again, from the top of the file to the bottom of the file, and get the exact same results each time. I should be able to run your code, from scratch, again and again, and get the exact same results that you get.\n",
        "  - Submit code that is organized. Make your code readable. Provide comments to describe what the code is doing and why. Don’t leave “old” code lying around. Overall, if your code is clear and easy to read, then we will be happy. When we are happy, we give better marks.\n",
        "\n",
        "For tasks that require **text responses**:\n",
        "- Type your response in Notebook cell indicated.\n",
        "- Use English. Use proper grammar, spelling, and punctuation. Be professional and clear. Be complete, but not overly verbose.\n",
        "- Feel free to use [Markdown syntax](https://www.markdownguide.org/basic-syntax/) to format your answer (i.e., add bold, italics, lists, tables).\n",
        "- You may refer to your code in your answer. Please do so very clearly. E.g., “As can be seen in on line X above …“\n",
        "\n",
        "\n",
        "## What to Submit to the Course Portal\n",
        "\n",
        "- You are to export your completed Notebook as a PDF file by clicking File->Print->Save as PDF.\n",
        "- Please do not submit the Notebook (.ipynb) file to the course portal. \n",
        "- Please submit the PDF export of the Notebook. \n",
        "   - Please name the PDF file 21_891_FirstnameLastName.pdf\n",
        "      - E.g., *21_891_StephenThomas.pdf*\n",
        "   - Please make sure you have run all the cells so we can see the output!\n",
        "   - Best practice: Before exporting to PDF, click Runtime->Restart and run all.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZFTCX4DqmRO"
      },
      "source": [
        "# Preliminaries: Inspect and Set up environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YXvDdiTYhdn",
        "outputId": "2e83e31d-04ef-4910-df22-57b96d74dd4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.7/dist-packages (1.3.4)\n",
            "Requirement already satisfied: Lime in /usr/local/lib/python3.7/dist-packages (0.2.0.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from Lime) (1.4.1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.7/dist-packages (from Lime) (0.18.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from Lime) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from Lime) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from Lime) (1.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from Lime) (4.64.0)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->Lime) (7.1.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->Lime) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->Lime) (1.3.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->Lime) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->Lime) (2.6.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->Lime) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->Lime) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->Lime) (3.0.8)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->Lime) (1.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->Lime) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->Lime) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->Lime) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->Lime) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers tfds-nightly\n",
        "!pip install unidecode\n",
        "!pip install Lime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xj34Jz-Do_oK",
        "outputId": "95e1ffb4-187e-4565-ff1f-3353d4abb565"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import unidecode\n",
        "import nltk\n",
        "from nltk.corpus import stopwords  \n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "import re\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "# matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn')\n",
        "\n",
        "try: # this is only working on the 2nd try in colab :)\n",
        "  from transformers import DistilBertTokenizer, TFDistilBertModel, DistilBertConfig, AutoTokenizer, AutoModel, AutoConfig\n",
        "except Exception as err: # so we catch the error and import it again\n",
        "  from transformers import DistilBertTokenizer, TFDistilBertModel, DistilBertConfig, AutoTokenizer, AutoModel, AutoConfig\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout, Flatten\n",
        "import lime\n",
        "from lime import lime_text\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from lime.lime_text import LimeTextExplainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqQ_XOKyXTS6",
        "outputId": "505c91f8-f85f-4edc-88f4-5c79fef0433e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-30 00:37:17.677547\n"
          ]
        }
      ],
      "source": [
        "print(datetime.datetime.now())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfOMt1lErLhZ",
        "outputId": "fcc0ce13-4592-430f-c88f-93bf01b0a99e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/bin/python\n"
          ]
        }
      ],
      "source": [
        "!which python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aub2w1-arM5K",
        "outputId": "8538dd42-f415-4b4f-ca46-b4a05ac85c0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.13\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9Y_n_8UrO9i",
        "outputId": "b7f251b5-d3f7-414b-97dd-e6454ca52634"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/env/python\n"
          ]
        }
      ],
      "source": [
        "!echo $PYTHONPATH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qj1NSQelo_oN"
      },
      "source": [
        "# Question 1: Sentiment Analysis via Shallow ML\n",
        "\n",
        "\n",
        "**Marking**\n",
        "\n",
        "The coding parts (i.e., 1.a, 1.b, 1.c4) will be marked based on:\n",
        "\n",
        "- *Correctness*. Code clearly and fully performs the task specified.\n",
        "- *Reproducibility*. Code is fully reproducible. I.e., you (and I) are able to run this Notebook again and again, from top to bottom, and get the same results each time.\n",
        "- *Style*. Code is organized. All parts commented with clear reasoning and rationale. No old code laying around. Code easy to follow.\n",
        "\n",
        "\n",
        "Parts 2 and 3 will be marked on:\n",
        "\n",
        "- *Quality*. Response is well-justified and convincing. Responses uses facts and data where possible.\n",
        "- *Style*. Response uses proper grammar, spelling, and punctuation. Response is clear and professional. Response is complete, but not overly-verbose. Response follows length guidelines.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60UNWiX8YmLi",
        "outputId": "200ecef9-2f10-4695-9a5a-3aaa31065e64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2400 entries, 0 to 2399\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Sentence  2400 non-null   object\n",
            " 1   Polarity  2400 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 37.6+ KB\n"
          ]
        }
      ],
      "source": [
        "# DO NOT MODIFY THIS CELL\n",
        "\n",
        "# First, we'll read the provided labeled training data\n",
        "df = pd.read_csv(\"https://drive.google.com/uc?export=download&id=1b8MAiN-xBdk6scM-DnufkuijDZivZJqM\")\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pxNvVO7FBnVt",
        "outputId": "6e476689-3e94-46cf-fb64-271137849df9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Sentence  Polarity\n",
              "0                           Wow... Loved this place.         1\n",
              "1                                 Crust is not good.         0\n",
              "2          Not tasty and the texture was just nasty.         0\n",
              "3  Stopped by during the late May bank holiday of...         1\n",
              "4  The selection on the menu was great and so wer...         1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-26bafd63-c57e-4ae7-b99b-dd66a54d9509\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-26bafd63-c57e-4ae7-b99b-dd66a54d9509')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-26bafd63-c57e-4ae7-b99b-dd66a54d9509 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-26bafd63-c57e-4ae7-b99b-dd66a54d9509');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "ksKqf_fV6pIO"
      },
      "outputs": [],
      "source": [
        "# DO NOT MODIFY THIS CELL\n",
        "\n",
        "# Next, we'll split it into training and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df['Sentence']\n",
        "y = df['Polarity']\n",
        "\n",
        "# So that we can evaluate how well our model is performing, we split our training data\n",
        "# into training and validation.\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R04NzckZKbG2"
      },
      "source": [
        "## Part 1.a: Preprocessing and FE Pipeline\n",
        "\n",
        "Clean and preprocess the data (i.e., `X_train`) as you see necessary. Extract features from the text (i.e., vectorization using BOW and/or Bag of N-Grams and/or topics and/or lexical features). \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qeavkicwo_oN",
        "outputId": "85600cc7-eba7-4af1-d6f8-ec53557ba348"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 552 ms, sys: 14.7 ms, total: 567 ms\n",
            "Wall time: 581 ms\n",
            "CPU times: user 138 ms, sys: 2.94 ms, total: 141 ms\n",
            "Wall time: 140 ms\n"
          ]
        }
      ],
      "source": [
        "stop_words = stopwords.words('english') \n",
        "lemmer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess(x):\n",
        "    # Remove HTML tags\n",
        "    x = BeautifulSoup(x, \"lxml\").get_text()\n",
        "\n",
        "    # Lower case\n",
        "    x = x.lower()\n",
        "    \n",
        "    # Remove punctuation\n",
        "    x = re.sub(r'[^\\w\\s]', '', x)\n",
        "    \n",
        "    # Remove non-unicode\n",
        "    x = unidecode.unidecode(x)\n",
        "    \n",
        "    # Remove numbers\n",
        "    x = re.sub(r'\\d+', '', x)\n",
        "    \n",
        "    # Remove stopwords and lemmatize\n",
        "    x = [lemmer.lemmatize(w) for w in x.split() if w not in stop_words]\n",
        "    return ' '.join(x) \n",
        "\n",
        "%time X_train_Clean = X_train.apply(preprocess)\n",
        "%time X_val_Clean = X_val.apply(preprocess)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note** - On multiple trials for cleaning data, it actually reduced the overall accuracy. So, in below code, will avoid using cleaned data."
      ],
      "metadata": {
        "id": "RkHkXNvOfy_l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "4gGwwioMmqaD"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "#vectorizer = TfidfVectorizer(max_features = None, ngram_range=[1,4], min_df = 1, max_df = 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note** - Using different hyperparameters for TfidVec doesn't help either. So, using plain vanilla and it got the best accuracy."
      ],
      "metadata": {
        "id": "d25waAqOgDEb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7FIkMnao_oO"
      },
      "source": [
        "## Part 1.b: Model Training/Tuning/Cross Validation\n",
        "\n",
        "Use your favorite shallow ML algorithm (such as decision trees, KNN, random forest, boosting variants) to train a classification model.  Don’t forget everything we’ve learned in the machine learning course: hyperparameter tuning, cross-validation, handling imbalanced data, etc. Make reasonable decisions and try to create the best-performing model that you can.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Random Forest Model"
      ],
      "metadata": {
        "id": "Khj8gD78gb5y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "id": "cgek8ghwo_oP"
      },
      "outputs": [],
      "source": [
        "pipe = Pipeline([('vec', vectorizer),  ('clf', RandomForestClassifier(random_state=223))])\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "pred_val = pipe.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_val, pred_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpJSl6eKYZ24",
        "outputId": "a96f9d8e-3f16-4f25-c91f-9ad2ed464454"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.79      0.80       323\n",
            "           1       0.76      0.78      0.77       277\n",
            "\n",
            "    accuracy                           0.79       600\n",
            "   macro avg       0.79      0.79      0.79       600\n",
            "weighted avg       0.79      0.79      0.79       600\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###XGBoost Model"
      ],
      "metadata": {
        "id": "wEoSbLFkggLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_xgb = Pipeline([('vec', vectorizer),  ('xgb', XGBClassifier(random_state=223))])\n",
        "\n",
        "pipe_xgb.fit(X_train, y_train)\n",
        "\n",
        "pred_val_xgb = pipe_xgb.predict(X_val)\n",
        "print(classification_report(y_val, pred_val_xgb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jtc7RvReMUR",
        "outputId": "350e43de-7a5e-4f03-de07-3138c906fc2d"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.84      0.79       323\n",
            "           1       0.79      0.68      0.73       277\n",
            "\n",
            "    accuracy                           0.77       600\n",
            "   macro avg       0.77      0.76      0.76       600\n",
            "weighted avg       0.77      0.77      0.76       600\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Naive Bayes Model"
      ],
      "metadata": {
        "id": "dsPvafNnl-YF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_nb = Pipeline([('vec', vectorizer),  ('nb', MultinomialNB())])\n",
        "\n",
        "pipe_nb.fit(X_train, y_train)\n",
        "\n",
        "pred_val_nb = pipe_nb.predict(X_val)\n",
        "print(classification_report(y_val, pred_val_nb))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkOzKVX6mCj3",
        "outputId": "7def612d-0d6e-4604-848d-5be9e7e35c28"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.84      0.83       323\n",
            "           1       0.80      0.79      0.80       277\n",
            "\n",
            "    accuracy                           0.81       600\n",
            "   macro avg       0.81      0.81      0.81       600\n",
            "weighted avg       0.81      0.81      0.81       600\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Linear SVC Model"
      ],
      "metadata": {
        "id": "CyOcPQb5hlif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKwnMk_YjANo",
        "outputId": "f2ac3e32-f100-4100-d49b-f6e587eb08c3"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1800,)"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Pipeline and Fit model\n",
        "pipe_lsvc = Pipeline([('vec', vectorizer),  \n",
        "                    ('ls', LinearSVC())])\n",
        "\n",
        "pipe_lsvc.fit(X_train, y_train)\n",
        "\n",
        "pred_val_lsvc = pipe_lsvc.predict(X_val)\n",
        "print(classification_report(y_val, pred_val_lsvc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jJLhJnahqQe",
        "outputId": "5c36c14e-f16c-4969-9284-8b96103287b6"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.85       323\n",
            "           1       0.84      0.81      0.83       277\n",
            "\n",
            "    accuracy                           0.84       600\n",
            "   macro avg       0.84      0.84      0.84       600\n",
            "weighted avg       0.84      0.84      0.84       600\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjUgRW1N6ppS"
      },
      "source": [
        "## Part 1.c: Model Assessment \n",
        "\n",
        "Use your model to predict the sentiment of the testing data. Measure the performance (e.g., accuracy, AUC, F1-score) of your model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYlrWng9MqmL",
        "outputId": "4dcdf3cf-b0ca-44f6-cc44-ae4c1f439821"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 600 entries, 0 to 599\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Sentence  600 non-null    object\n",
            " 1   Polarity  600 non-null    int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 9.5+ KB\n"
          ]
        }
      ],
      "source": [
        "# DO NOT MODIFY THIS CELL\n",
        "\n",
        "test_df = pd.read_csv(\"https://drive.google.com/uc?export=download&id=1taoTluPBUMt9JkKAnlqDTrU49DJFpJGW\")\n",
        "test_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zDX1dg4nPEz",
        "outputId": "53df9e47-76f2-4464-f666-2cab4165f6c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 272 ms, sys: 1.77 ms, total: 274 ms\n",
            "Wall time: 402 ms\n"
          ]
        }
      ],
      "source": [
        "#Will not use cleaned test data, due to low accuracy\n",
        "%time test_df['Sentence_clean'] = test_df['Sentence'].apply(preprocess)\n",
        "y_test = test_df['Polarity']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###XGBoost Test"
      ],
      "metadata": {
        "id": "UJNi4auRfB2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_test_xgb = pipe_xgb.predict(test_df['Sentence'])\n",
        "\n",
        "pred_test_prob_xgb = pipe_xgb.predict_proba(test_df['Sentence'])\n",
        "print(classification_report(y_test, pred_test_xgb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzPJ0B5JfBCI",
        "outputId": "6eabe7ff-e63b-4ac5-b1bf-c8f8b7da93c9"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.83      0.69       287\n",
            "           1       0.75      0.46      0.57       313\n",
            "\n",
            "    accuracy                           0.64       600\n",
            "   macro avg       0.67      0.65      0.63       600\n",
            "weighted avg       0.67      0.64      0.63       600\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Random Forest Test"
      ],
      "metadata": {
        "id": "EpDGfLm2fJwF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "id": "yMm6r-wSOUY1"
      },
      "outputs": [],
      "source": [
        "pred_test = pipe.predict(test_df['Sentence'])\n",
        "\n",
        "pred_test_prob = pipe.predict_proba(test_df['Sentence'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6IOygjXnk8J",
        "outputId": "b39bde7f-3d1d-43c7-c826-80576034d42d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.82      0.72       287\n",
            "           1       0.78      0.58      0.67       313\n",
            "\n",
            "    accuracy                           0.69       600\n",
            "   macro avg       0.71      0.70      0.69       600\n",
            "weighted avg       0.71      0.69      0.69       600\n",
            "\n",
            "auc_score_test: 0.7731128452316016\n",
            "accuracy 0.695\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, pred_test))\n",
        "fpr, tpr, thresh = roc_curve(y_test, pred_test_prob[:,1], pos_label=1)\n",
        "\n",
        "# roc curve for tpr = fpr \n",
        "random_probs = [0 for i in range(len(y_test))]\n",
        "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)\n",
        "\n",
        "auc_score = roc_auc_score(y_test, pred_test_prob[:,1])\n",
        "\n",
        "print('auc_score_test:',auc_score)\n",
        "print('accuracy %s' % accuracy_score(pred_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Naive Bayes Test"
      ],
      "metadata": {
        "id": "c1jpTMTBmbvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_test_nb = pipe_nb.predict(test_df['Sentence'])\n",
        "\n",
        "pred_test_prob_nb = pipe_nb.predict_proba(test_df['Sentence'])\n",
        "print(classification_report(y_test, pred_test_nb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIsAdnLxmfKo",
        "outputId": "83b06a47-c277-4adc-ff55-e6f2455ff64b"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.85      0.78       287\n",
            "           1       0.84      0.70      0.77       313\n",
            "\n",
            "    accuracy                           0.78       600\n",
            "   macro avg       0.78      0.78      0.77       600\n",
            "weighted avg       0.78      0.78      0.77       600\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Linear SVC Test"
      ],
      "metadata": {
        "id": "nu3seVAxkJ0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_test_lsvc = pipe_lsvc.predict(test_df['Sentence'])\n",
        "\n",
        "print(classification_report(y_test, pred_test_lsvc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GXw0cIWkJfB",
        "outputId": "008f3af1-1046-4e26-ffe4-ee14bf40f8ed"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.79      0.76       287\n",
            "           1       0.79      0.72      0.76       313\n",
            "\n",
            "    accuracy                           0.76       600\n",
            "   macro avg       0.76      0.76      0.76       600\n",
            "weighted avg       0.76      0.76      0.76       600\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wUBcyrdM3__"
      },
      "source": [
        "## Part 2: Given the performance of your model, are you satisfied with the results? Explain.\n",
        "\n",
        "Keep your response to 1000 characters or less."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oCr-mTfNG-H"
      },
      "source": [
        "Given that we are using shallow ML for classification, in my opinion we got good accuracy score. We have tried cleaning data, TfIdfVec hyper parameter tuning etc. In the end, models performed better without those steps. So, I can say I am satisfied with the steps tried in this problem.\n",
        "\n",
        "\n",
        "*   Best Model - Naive Bayes - 78% Accuracy\n",
        "*   No preprocessing of data needed\n",
        "*   No hyperparameter tuning worked for TfIdfVec or for models we have tried, which could improve the score.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sz8dTvnJNKLL"
      },
      "source": [
        "## Part 3: Show five test instances in which your model was incorrect. Dive deep and find out why your model was wrong.\n",
        "\n",
        "Keep your response to 1000 characters or less."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyEMIxPkpryA",
        "outputId": "bfe54e6a-a5b8-49b6-bd08-3ea9b9b38d3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample (3, \"It's a feel-good film and that's how I felt when I came out of the cinema!  \") , has been classified as 0 and should be 1\n",
            "Sample (12, 'Not too screamy not to masculine but just right.  ') , has been classified as 0 and should be 1\n",
            "Sample (14, 'I would have casted her in that role after ready the script.  ') , has been classified as 0 and should be 1\n",
            "Sample (26, 'I wish I could enter negative values, admins?  ') , has been classified as 1 and should be 0\n",
            "Sample (34, '1/10 - and only because there is no setting for 0/10.  ') , has been classified as 1 and should be 0\n",
            "Sample (36, \"The soundtrack wasn't terrible, either.  \") , has been classified as 0 and should be 1\n",
            "Sample (38, 'Still, it was the SETS that got a big \"10\" on my \"oy-vey\" scale.  ') , has been classified as 0 and should be 1\n",
            "Sample (39, 'Yes, I am simplifying things here for the sake of brevity, for this really is at the core of the problems with this film - it has too much going on without any real, fulfilling explanation.  ') , has been classified as 1 and should be 0\n",
            "Sample (43, 'The last 15 minutes of movie are also not bad as well.  ') , has been classified as 0 and should be 1\n",
            "Sample (46, \"I like Armand Assante & my cable company's summary sounded interesting, so I watched it, twice already, and probably will again.  \") , has been classified as 0 and should be 1\n",
            "Sample (47, 'I believe the screenwriter did a good job of tying up the loose ends.  ') , has been classified as 0 and should be 1\n",
            "Sample (48, 'My 8/10 score is mostly for the plot.  ') , has been classified as 0 and should be 1\n",
            "Sample (49, \"I won't say any more - I don't like spoilers, so I don't want to be one, but I believe this film is worth your time.  \") , has been classified as 0 and should be 1\n",
            "Sample (53, 'Not even good for camp value!  ') , has been classified as 1 and should be 0\n",
            "Sample (58, \"This gets a 1 out of 10, simply because there's nothing lower.  \") , has been classified as 1 and should be 0\n",
            "Sample (66, 'Whatever the producer was going for, he missed entirely.  ') , has been classified as 1 and should be 0\n",
            "Sample (77, 'The directing is sloppy at best.  ') , has been classified as 1 and should be 0\n",
            "Sample (80, 'The acting by the whole cast could be put on a scale and balanced perfectly between overacting and underacting.  ') , has been classified as 1 and should be 0\n",
            "Sample (81, \"And, FINALLY, after all that, we get to an ending that would've been great had it been handled by competent people and not Jerry Falwell.  \") , has been classified as 1 and should be 0\n",
            "Sample (84, \"This movie contained an all-star cast, and what I loved the most was that it opened my eyes to see other actors who I haven't seen before.  \") , has been classified as 0 and should be 1\n",
            "Sample (87, 'Lifetime does not air it enough, so if anyone knows what store sells it let me know because this is a must-have.  ') , has been classified as 0 and should be 1\n",
            "Sample (90, 'Totally different, with loads of understatement and black comedy, this is a film few get to see, but those who do will remember it.  ') , has been classified as 0 and should be 1\n",
            "Sample (92, 'But this movie really got to me.  ') , has been classified as 0 and should be 1\n",
            "Sample (93, 'See it.  ') , has been classified as 0 and should be 1\n",
            "Sample (94, 'I really hope the team behind this movie makes more movies, and that they will continue to do so in their own, some kinda weird style.  ') , has been classified as 0 and should be 1\n",
            "Sample (98, 'Initially the local sites in the film, which was filmed here in Buffalo, intrigued me.  ') , has been classified as 0 and should be 1\n",
            "Sample (99, 'Later I found myself lost in the power of the film.  ') , has been classified as 0 and should be 1\n",
            "Sample (124, 'Full of unconvincing cardboard characters it is blandly written by Edward Chodorov, who also produced, and is surprisingly directed by Jean Negulesco from whom one would expect a great deal more.  ') , has been classified as 1 and should be 0\n",
            "Sample (126, 'His losing his marbles so early in the proceedings is totally implausible and unconvincing.  ') , has been classified as 1 and should be 0\n",
            "Sample (128, 'Whatever prompted such a documentary is beyond me!  ') , has been classified as 1 and should be 0\n",
            "Sample (139, 'i wouldnt see this movie again for free.  ') , has been classified as 1 and should be 0\n",
            "Sample (141, 'This second appearance of Mickey Mouse (following the silent PLANE CRAZY earlier that year) is probably his most famous film--mostly because it was so ground-breaking.  ') , has been classified as 0 and should be 1\n",
            "Sample (142, \"While you don't yet hear Mickey speak, there are tons of sound effects and music throughout the film--something we take for granted now but which was a huge crowd pleaser in 1928.  \") , has been classified as 0 and should be 1\n",
            "Sample (147, \"I'm terribly disappointed that this film would receive so many awards and accolades, especially when there are far more deserving works of film out there.  \") , has been classified as 1 and should be 0\n",
            "Sample (154, \"It's a shame to see good actors like Thomerson and James make a living in a mess like this.  \") , has been classified as 1 and should be 0\n",
            "Sample (172, 'Not recommended.  ') , has been classified as 1 and should be 0\n",
            "Sample (179, 'The budget was evidently very limited.  ') , has been classified as 1 and should be 0\n",
            "Sample (182, 'Filmiing was less expansive.  ') , has been classified as 1 and should be 0\n",
            "Sample (183, 'It failed to convey the broad sweep of landscapes that were a great part of the original.  ') , has been classified as 1 and should be 0\n",
            "Sample (185, 'Not recommended.  ') , has been classified as 1 and should be 0\n",
            "Sample (195, 'Easily, none other cartoon made me laugh in a tender way (before getting into dark sitcoms oriented for teenagers).  ') , has been classified as 0 and should be 1\n",
            "Sample (198, 'Every element of this story was so over the top, excessively phony and contrived that it was painful to sit through.  ') , has been classified as 1 and should be 0\n",
            "Sample (204, 'To be honest with you, this is unbelievable nonsense and very foolish.  ') , has been classified as 1 and should be 0\n",
            "Sample (208, 'And the accents are absolutely abysmal!  ') , has been classified as 1 and should be 0\n",
            "Sample (211, 'I believe that Pitch Black was done well.  ') , has been classified as 0 and should be 1\n",
            "Sample (212, \"The characters are interesting and you want to find out more about them the longer the movie goes on, and I think people will be surprised by who does and doesn't make it.  \") , has been classified as 0 and should be 1\n",
            "Sample (213, 'Go watch it!  ') , has been classified as 0 and should be 1\n",
            "Sample (216, 'My rating: just 3 out of 10.  ') , has been classified as 1 and should be 0\n",
            "Sample (219, \"Don't miss it.  \") , has been classified as 0 and should be 1\n",
            "Sample (238, 'I have to say that this film was excellently produced and tops the ratings as a typical sci fi film!  ') , has been classified as 0 and should be 1\n",
            "Sample (242, \"There's barely a boring moment in the film and there are plenty of humorous parts.  \") , has been classified as 0 and should be 1\n",
            "Sample (249, 'I believe every one should see this movie as I think few people outside of South Africa understand its past and what is being attempted in the Truth and Reconciliation process.  ') , has been classified as 0 and should be 1\n",
            "Sample (252, \"Don't be afraid of subtitles........ its worth a little aversion therapy 10/10  \") , has been classified as 0 and should be 1\n",
            "Sample (258, 'Helen Baxendale is a very credible lady Macbeth who can be very cheerfull at times and sometimes she just looks like a naughty girl, but deadly in her taste for blood and evil.  ') , has been classified as 0 and should be 1\n",
            "Sample (268, 'Speaking of the music, it is unbearably predictably and kitchy.  ') , has been classified as 1 and should be 0\n",
            "Sample (271, 'Raw and sublimely moving.  ') , has been classified as 0 and should be 1\n",
            "Sample (273, 'All of the main players are mesmerising.  ') , has been classified as 0 and should be 1\n",
            "Sample (275, 'Julian Fellowes has triumphed again.  ') , has been classified as 0 and should be 1\n",
            "Sample (281, 'The film gives meaning to the phrase, \"Never in the history of human conflict has so much been owed by so many to so few.  ') , has been classified as 0 and should be 1\n",
            "Sample (291, 'Shot in the Southern California desert using his patent faux documentary style, Watkins creates a film like no other.  ') , has been classified as 0 and should be 1\n",
            "Sample (293, 'I advise you to look out for it.  ') , has been classified as 0 and should be 1\n",
            "Sample (294, 'You wont regret it!  ') , has been classified as 0 and should be 1\n",
            "Sample (303, 'The results, well, are a shame.  ') , has been classified as 1 and should be 0\n",
            "Sample (310, 'The stories were as unbelievable as the actors.  ') , has been classified as 1 and should be 0\n",
            "Sample (316, 'The lines, the cuts, the audio, everything is wrong.  ') , has been classified as 1 and should be 0\n",
            "Sample (321, \"So mediocre in every aspect that it just becomes a dull, uninteresting mess, this is one of the most forgettable movies I've seen.  \") , has been classified as 1 and should be 0\n",
            "Sample (334, \"It's one of the movies I need to see whenever it comes on TV...never mind the fact that I already have it memorized!  \") , has been classified as 0 and should be 1\n",
            "Sample (336, 'That was done in the second movie.  ') , has been classified as 1 and should be 0\n",
            "Sample (348, \"I'm a big fan of this series mostly due to Anne Rice's style, sensitivities and treatments.  \") , has been classified as 0 and should be 1\n",
            "Sample (349, 'I guess I liked the details of his dysfunction--he was believable.  ') , has been classified as 0 and should be 1\n",
            "Sample (351, 'But I thought his acting was skilled.  ') , has been classified as 0 and should be 1\n",
            "Sample (354, \"It is rare when a film-maker takes the time to tell a worthy moral tale with care and love that doesn't fall into the trap of being overly syrupy or over indulgent.  \") , has been classified as 0 and should be 1\n",
            "Sample (358, 'A standout scene.  ') , has been classified as 0 and should be 1\n",
            "Sample (359, 'This scene is very strong and unpleasant.  ') , has been classified as 1 and should be 0\n",
            "Sample (363, \"I liked the way Dustin Hoffman's character was ready to do just about everything to stay with his son.  \") , has been classified as 0 and should be 1\n",
            "Sample (365, 'Personally, I think it shows that people should learn to find a compromise them self without involving other people into issue.  ') , has been classified as 0 and should be 1\n",
            "Sample (367, 'I am so tired of clichés that is just lazy writing, and here they come in thick and fast.  ') , has been classified as 1 and should be 0\n",
            "Sample (368, 'PS the only scene in the movie that was cool is when the central character finds her room blown up.  ') , has been classified as 0 and should be 1\n",
            "Sample (372, 'You learn a lot about the real inside emotions of people in this movie, and a lot about the movie business itself.  ') , has been classified as 0 and should be 1\n",
            "Sample (375, \"You won't forget this movie!  \") , has been classified as 0 and should be 1\n",
            "Sample (377, 'The film has an ultra-cheap look to it.  ') , has been classified as 1 and should be 0\n",
            "Sample (383, \"But the duet between the astronaut and his doctor at the beginning of the movie is a perfect exchange if one considers that this movie was made well into the Cold War and the astronaut's biggest fear is that he has crashed in the USSR.  \") , has been classified as 0 and should be 1\n",
            "Sample (387, 'If you want a real scare rent this one!  ') , has been classified as 0 and should be 1\n",
            "Sample (391, \"This film highlights the fundamental flaws of the legal process, that it's not about discovering guilt or innocence, but rather, is about who presents better in court.  \") , has been classified as 0 and should be 1\n",
            "Sample (394, 'Predictable, but not a bad watch.  ') , has been classified as 0 and should be 1\n",
            "Sample (395, 'It was clear that she had the range and ability to pull off this part.  ') , has been classified as 0 and should be 1\n",
            "Sample (400, 'In fact, this stinker smells like a direct-to-video release.  ') , has been classified as 1 and should be 0\n",
            "Sample (405, 'The only place good for this film is in the garbage.  ') , has been classified as 1 and should be 0\n",
            "Sample (408, \"When a song could explain the emotions of the subjects better, such as when Jay Adams' unfortunate life was a subject of talk, the song Old Man by Neil Young was played, which evokes many emotions.  \") , has been classified as 0 and should be 1\n",
            "Sample (410, 'Of course the footage from the 70s was grainy, but that only enhanced the film.  ') , has been classified as 0 and should be 1\n",
            "Sample (415, 'But this understated film leaves a lasting impression.  ') , has been classified as 0 and should be 1\n",
            "Sample (417, 'You will leave the theater wanting to go out and dance under the stars.  ') , has been classified as 0 and should be 1\n",
            "Sample (422, \"It's a long time since I was so entertained by a movie.  \") , has been classified as 0 and should be 1\n",
            "Sample (423, 'I struggle to find anything bad to say about it.  ') , has been classified as 0 and should be 1\n",
            "Sample (426, \"The film deserves strong kudos for taking this stand, for having exceptional acting from its mostly lesser-known cast and for the super-intelligent script that doesn't insult the audience or take the easy way out when it comes to white racism.  \") , has been classified as 0 and should be 1\n",
            "Sample (432, 'It was that year, however, that reminded us that Huston was still at the top of his game as evinced by his faithful adaptation of James Joyce\\'s acclaimed novella \"The Dead.  ') , has been classified as 0 and should be 1\n",
            "Sample (443, \"It has everything you could want... suspense, drama, comedy, confusing subplots, native americans, brain eating... If you're looking for the be-all, end-all of brainsucking movies, look no further.  \") , has been classified as 0 and should be 1\n",
            "Sample (445, 'Call me a nut, but I think this is one of the best movies ever.  ') , has been classified as 0 and should be 1\n",
            "Sample (450, 'Now imagine that every single one of those decisions was made wrong.  ') , has been classified as 1 and should be 0\n",
            "Sample (453, 'Everything stinks.  ') , has been classified as 1 and should be 0\n",
            "Sample (459, \"The best scene in the movie is at the end, but I won't spoil it.  \") , has been classified as 0 and should be 1\n",
            "Sample (460, \"If there was ever an indication of a writer and a director's ability to meld two highly volatile temperaments into a seamless union of creativity, then this is it!  \") , has been classified as 0 and should be 1\n",
            "Sample (461, \"The result is a powerhouse achievement, made more timely now perhaps because of our culture's disturbing fascination with celebrity, and it's distorted interpretations of fame.  \") , has been classified as 0 and should be 1\n",
            "Sample (462, 'A film not easily forgotten.  ') , has been classified as 0 and should be 1\n",
            "Sample (465, 'The characters are interesting, even if a bit predictable.  ') , has been classified as 0 and should be 1\n",
            "Sample (466, 'Highly recommended for all ages, although the younger set will probably not appreciate some of the more subtle references, they will certainly appreciate one galley scene in particular!  ') , has been classified as 0 and should be 1\n",
            "Sample (472, 'The story starts too fast with absolutely no suspense or build-up in the slightest.  ') , has been classified as 1 and should be 0\n",
            "Sample (487, 'At any rate this film stinks, its not funny, and Fulci should have stayed with giallo and supernatural zombie movies.  ') , has been classified as 1 and should be 0\n",
            "Sample (490, 'The only consistent thread holding the series together were the amazing performances of Leni Parker and Anita LaSelva as the two Taelons in quiet idealogical conflict.  ') , has been classified as 1 and should be 0\n",
            "Sample (491, 'Now this is a movie I really dislike.  ') , has been classified as 1 and should be 0\n",
            "Sample (499, 'Director Neil LaBute uses brutal violence to seperate dreams from reality, and along with the touching drama, and hilarious comedy, you can never tell what is going to happen next.  ') , has been classified as 0 and should be 1\n",
            "Sample (503, 'There is, however, some pretty good acting (at least, for this type of film).  ') , has been classified as 0 and should be 1\n",
            "Sample (515, \"I didn't realize how wonderful the short really is until the last two scenes.  \") , has been classified as 0 and should be 1\n",
            "Sample (517, 'Hopefully, the director James Cox can turn the short into a feature length film with the same cast, or win us over with a whole new film.  ') , has been classified as 0 and should be 1\n",
            "Sample (519, 'Characters are one-dimensional, even the good guys and especially the bad guys.  ') , has been classified as 1 and should be 0\n",
            "Sample (521, 'Not much dialogue, not much music, the whole film was shot as elaborately and aesthetically like a sculpture.  ') , has been classified as 0 and should be 1\n",
            "Sample (526, \"Funny, clever, hip - just like Pray's previous film, Hype!  \") , has been classified as 0 and should be 1\n",
            "Sample (527, \"It was a long time that i didn't see a so charismatic actor on screen.  \") , has been classified as 0 and should be 1\n",
            "Sample (529, \"The movie is not completely perfect but 'Titta Di Girolamo' will stay with you for a long time after the vision of the movie.  \") , has been classified as 0 and should be 1\n",
            "Sample (531, \"I do not know if this was Emilio Estevez's directorial debut, but the pacing, the interplay and development of the characters as well as some clever camera work surrounding the character Estevez plays all suggest a natural eye.  \") , has been classified as 0 and should be 1\n",
            "Sample (536, 'The two main characters may be two of the most believable children I ever saw put on screen.  ') , has been classified as 0 and should be 1\n",
            "Sample (543, 'Go rent it.  ') , has been classified as 0 and should be 1\n",
            "Sample (544, 'However, after finally watching this film, I realized that not only had I had a closed mind to the brilliance it depicts, I also found myself watching it over and over again.  ') , has been classified as 0 and should be 1\n",
            "Sample (545, \"It's the one movie that never ceases to interest me, simply because it keeps me alert, as I try to attempt to decipher it's meanings.  \") , has been classified as 0 and should be 1\n",
            "Sample (548, 'Think of the film being like a dream.  ') , has been classified as 0 and should be 1\n",
            "Sample (556, 'But it picked up speed and got right to the point.  ') , has been classified as 0 and should be 1\n",
            "Sample (563, \"The film's dialogue is natural, real to life.  \") , has been classified as 0 and should be 1\n",
            "Sample (564, 'The writer, Gorman Bechard, undoubtedly did his homework because all references are industry and character-age appropriate.  ') , has been classified as 0 and should be 1\n",
            "Sample (570, 'Enough can not be said of the remarkable animation in this film.  ') , has been classified as 0 and should be 1\n",
            "Sample (578, 'Then I watched it again two Sundays ago (March 20th, 2005) and I began to really enjoy it and this time I taped the entire thing.  ') , has been classified as 0 and should be 1\n",
            "Sample (581, 'I keep watching it over and over.  ') , has been classified as 0 and should be 1\n",
            "Sample (582, \"It's a sad movie, but very good.  \") , has been classified as 0 and should be 1\n",
            "Sample (583, 'If you have not seen this movie, I definitely recommend it!  ') , has been classified as 0 and should be 1\n",
            "Sample (589, ':) Anyway, the plot flowed smoothly and the male-bonding scenes were a hoot.  ') , has been classified as 0 and should be 1\n",
            "Sample (591, 'Fans of the genre will be in heaven.  ') , has been classified as 0 and should be 1\n"
          ]
        }
      ],
      "source": [
        "for idx, prediction, label in zip(enumerate(test_df['Sentence']), pred_test_nb, y_test):\n",
        "    if prediction != label:\n",
        "        print(\"Sample\", idx, ', has been classified as', prediction, 'and should be', label) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DekZ7mulNTmr"
      },
      "source": [
        "##Explanation\n",
        "Let's analyze following sentences which got wrongly predicted.\n",
        "1. **394** - 'Predictable, but not a bad watch.'  **[Pred-0;Actual-1]**\n",
        "2. **377** - 'The film has an ultra-cheap look to it.' **[Pred-1;Actual-0]**\n",
        "3. **211** - 'I believe that Pitch Black was done well.' **[Pred-0;Actual-1] **\n",
        "4.  **92** - 'But this movie really got to me.'  **[Pred-0;Actual-1]** \n",
        "5.  **12** - 'Not too screamy not to masculine but just right.'  **[Pred-0;Actual-1]**\n",
        "\n",
        "To explain which words contributed into prediction for sentence, we will use Lime library. This will show how our model behaving around the words in sentence, hence predicting the way it is.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize \n",
        "test_vectors = vectorizer.transform(test_df.Sentence)\n",
        "class_names=['Negative','Postive']\n",
        "explainer = LimeTextExplainer(class_names=class_names)"
      ],
      "metadata": {
        "id": "UwFma4HPRph5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###  Sentence-1 --> 'Predictable, but not a bad watch.' [Pred-0;Actual-1]  ####\n",
        "\n",
        "idx=394\n",
        "\n",
        "#We are using top 6 features from document, which impacted the model prediction \n",
        "exp = explainer.explain_instance(test_df.Sentence[idx], pipe_nb.predict_proba, num_features=6)\n",
        "print('Document id: %d' % idx)\n",
        "print('Probability Distribution: [Negative Postive]:',pipe_nb.predict_proba([test_df.Sentence[idx]]))\n",
        "print('Probability(Positive) =', pipe_nb.predict_proba([test_df.Sentence[idx]])[0,1])\n",
        "print('True class: %s' % class_names[test_df.Polarity[idx]])\n",
        "print(exp.as_list())\n",
        "%matplotlib inline\n",
        "fig = exp.as_pyplot_figure()\n",
        "\n",
        "###\n",
        "#  *** Conclusion *** - Explanation generated below shows, model predicted this sentence as 'negative'. This is due to the weightage given to words like 'bad','not'.\n",
        "###"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "DR24uGaROK67",
        "outputId": "1ff8dd61-3783-4282-cc26-dc142643a2a1"
      },
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document id: 394\n",
            "Probability Distribution: [Negative Postive]: [[0.92051611 0.07948389]]\n",
            "Probability(Positive) = 0.07948388983306906\n",
            "True class: Postive\n",
            "[('bad', -0.15210615785793577), ('not', -0.06759515242137619), ('watch', 0.03582295127497958), ('Predictable', -0.030396661871006894), ('but', -0.017256899155833966), ('a', -0.0032842816043386906)]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###  Sentence-2 --> 'The film has an ultra-cheap look to it.' [Pred-1;Actual-0]  ####\n",
        "\n",
        "idx=377\n",
        "\n",
        "#We are using top 6 features from document, which impacted the model prediction \n",
        "exp = explainer.explain_instance(test_df.Sentence[idx], pipe_nb.predict_proba, num_features=6)\n",
        "print('Document id: %d' % idx)\n",
        "print('Probability Distribution: [Negative Postive]:',pipe_nb.predict_proba([test_df.Sentence[idx]]))\n",
        "print('Probability(Positive) =', pipe_nb.predict_proba([test_df.Sentence[idx]])[0,1])\n",
        "print('True class: %s' % class_names[test_df.Polarity[idx]])\n",
        "print(exp.as_list())\n",
        "%matplotlib inline\n",
        "fig = exp.as_pyplot_figure()\n",
        "\n",
        "###\n",
        "#  *** Conclusion *** - Explanation generated below shows, model predicted this sentence as 'positive'. But its almost edge case. \n",
        "#                       Model considered words like 'has', 'an' as positive, which are stop words. We have not cleaned the test data, \n",
        "#                        and this is the reason for sentence to be classified as 'Positive'.\n",
        "###"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "kEbVn30qOPjs",
        "outputId": "19c4d3f6-9dd0-4310-f39d-db50ad65dc30"
      },
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document id: 377\n",
            "Probability Distribution: [Negative Postive]: [[0.47393828 0.52606172]]\n",
            "Probability(Positive) = 0.5260617179521474\n",
            "True class: Negative\n",
            "[('cheap', -0.16644840814323833), ('has', 0.06975730098098311), ('look', 0.06704494364269598), ('an', 0.040050356018806875), ('film', 0.016107174890182378), ('to', -0.012734797425341376)]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###  Sentence-3 --> 'I believe that Pitch Black was done well.' [Pred-0;Actual-1]  ####\n",
        "\n",
        "idx=211\n",
        "\n",
        "#We are using top 6 features from document, which impacted the model prediction \n",
        "exp = explainer.explain_instance(test_df.Sentence[idx], pipe_nb.predict_proba, num_features=6)\n",
        "print('Document id: %d' % idx)\n",
        "print('Probability Distribution: [Negative Postive]:',pipe_nb.predict_proba([test_df.Sentence[idx]]))\n",
        "print('Probability(Positive) =', pipe_nb.predict_proba([test_df.Sentence[idx]])[0,1])\n",
        "print('True class: %s' % class_names[test_df.Polarity[idx]])\n",
        "print(exp.as_list())\n",
        "%matplotlib inline\n",
        "fig = exp.as_pyplot_figure()\n",
        "\n",
        "###\n",
        "#  *** Conclusion *** - Explanation generated below shows, model predicted this sentence as 'negaive'. But again its edge case. \n",
        "#                       Model considered word 'believe' as negative, which shows it learns it as something where it comes with negative feeling.\n",
        "#                       Again, stop words 'that', 'was' contributed negatively. If we remove those, it may help model predictions.\n",
        "###"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "aQip1EjRTCYq",
        "outputId": "fd00fd8f-af80-49d1-bc65-ba8e061ce60b"
      },
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document id: 211\n",
            "Probability Distribution: [Negative Postive]: [[0.50860705 0.49139295]]\n",
            "Probability(Positive) = 0.49139294961103763\n",
            "True class: Postive\n",
            "[('believe', -0.12584985202674484), ('well', 0.10843209924570611), ('done', 0.06924484624150064), ('that', -0.03121805911657938), ('Black', -0.024418036899560305), ('was', -0.00977751035193135)]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###  Sentence-4 --> 'But this movie really got to me.' [Pred-0;Actual-1]  ####\n",
        "\n",
        "idx=92\n",
        "\n",
        "#We are using top 6 features from document, which impacted the model prediction \n",
        "exp = explainer.explain_instance(test_df.Sentence[idx], pipe_nb.predict_proba, num_features=6)\n",
        "print('Document id: %d' % idx)\n",
        "print('Probability Distribution: [Negative Postive]:',pipe_nb.predict_proba([test_df.Sentence[idx]]))\n",
        "print('Probability(Positive) =', pipe_nb.predict_proba([test_df.Sentence[idx]])[0,1])\n",
        "print('True class: %s' % class_names[test_df.Polarity[idx]])\n",
        "print(exp.as_list())\n",
        "%matplotlib inline\n",
        "fig = exp.as_pyplot_figure()\n",
        "\n",
        "###\n",
        "#  *** Conclusion *** - Explanation generated below shows, model predicted this sentence as 'negative'. \n",
        "#                       Again prediction for this sentence has been impacted by stop words like 'me', 'But', 'got'. \n",
        "#                       Interestingly, word 'movie' considered negative.\n",
        "###"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "FHAbCReFTDHt",
        "outputId": "7eab1011-5f27-4159-bdbd-f9de3947d991"
      },
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document id: 92\n",
            "Probability Distribution: [Negative Postive]: [[0.69734343 0.30265657]]\n",
            "Probability(Positive) = 0.3026565695535625\n",
            "True class: Postive\n",
            "[('me', -0.09862044337482448), ('But', -0.05461025993561304), ('really', 0.042853856326517815), ('movie', -0.02419675184637965), ('this', 0.019259646674771532), ('got', -0.018178961731164796)]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###  Sentence-5 --> 'Not too screamy not to masculine but just right.' [Pred-0;Actual-1]  ####\n",
        "\n",
        "idx=12\n",
        "\n",
        "#We are using top 6 features from document, which impacted the model prediction \n",
        "exp = explainer.explain_instance(test_df.Sentence[idx], pipe_nb.predict_proba, num_features=6)\n",
        "print('Document id: %d' % idx)\n",
        "print('Probability Distribution: [Negative Postive]:',pipe_nb.predict_proba([test_df.Sentence[idx]]))\n",
        "print('Probability(Positive) =', pipe_nb.predict_proba([test_df.Sentence[idx]])[0,1])\n",
        "print('True class: %s' % class_names[test_df.Polarity[idx]])\n",
        "print(exp.as_list())\n",
        "%matplotlib inline\n",
        "fig = exp.as_pyplot_figure()\n",
        "\n",
        "###\n",
        "#  *** Conclusion *** - Explanation generated below shows, model predicted this sentence as 'negative'.  \n",
        "#                       Model considered words like 'not', 'too', 'but' as negative, which are stop words, and heavily impacted prediction. \n",
        "###"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "Sm2UWnOITDwl",
        "outputId": "796ba90d-d011-4560-b39e-2d26b37e6b39"
      },
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document id: 12\n",
            "Probability Distribution: [Negative Postive]: [[0.80120347 0.19879653]]\n",
            "Probability(Positive) = 0.19879653442809891\n",
            "True class: Postive\n",
            "[('Not', -0.09563149257003534), ('not', -0.0938386725964851), ('right', 0.07418091585573386), ('too', -0.038547759109982836), ('but', -0.03642123310452276), ('just', 0.014925685170599216)]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bE2GL8VMNKHj"
      },
      "source": [
        "# Question 2 (Optional): Sentiment Analysis via Deep ML\n",
        "\n",
        "This question is optional and worth up to 5 extra credit marks.\n",
        "\n",
        "Use deep learning (e.g., RNNs and variants, CNNs and variants, and/or transformers) to build a model on the same dataset and compare the results with the Shallow ML model.\n",
        "\n",
        "You may train your own deep ML model (using, e.g., the keras library) or use a pre-trained deep ML model (using, e.g., the transformers library)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "id": "LhM3_13LRdTI"
      },
      "outputs": [],
      "source": [
        "# Creating Embeddings using DistilBERT \n",
        "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ltcz69A2vyu3",
        "outputId": "4174b337-f3e1-4743-84d9-bf27c15c2c26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The maximum amount of tokens in the dataset is 84\n"
          ]
        }
      ],
      "source": [
        "# Check longest token sequence in entire text\n",
        "def checkForMaxTokenSeqInData(text_list, tokenizer_i):\n",
        "  \n",
        "    max_val = 0\n",
        "    for sent in text_list:\n",
        "        try:\n",
        "            sent_tok_len = len(tokenizer_i.tokenize(sent))\n",
        "            max_val = sent_tok_len if (sent_tok_len > max_val) else max_val\n",
        "        except:\n",
        "            pass\n",
        "    \n",
        "    print(f\"The maximum amount of tokens in the dataset is {max_val}\")\n",
        "    return max_val\n",
        "\n",
        "MAX_VAL = checkForMaxTokenSeqInData(X_train.to_list()+X_val.to_list(),tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "id": "gCOtl0_mv3Xm"
      },
      "outputs": [],
      "source": [
        "def encode_text(tokenizer_i, text, max_text_length):\n",
        "\n",
        "    # Encode the sentence\n",
        "    encodedText = tokenizer_i(text,\n",
        "                             max_length =max_text_length,\n",
        "                            truncation=True, \n",
        "                            add_special_tokens=True, \n",
        "                            padding='max_length')\n",
        "    return encodedText\n",
        "\n",
        "train_encoding = encode_text(tokenizer, X_train.to_list(), MAX_VAL)\n",
        "val_encoding = encode_text(tokenizer, X_val.to_list(), MAX_VAL)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWLTzGYhwhb5"
      },
      "source": [
        "###Build Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLbhbOTlwEJY",
        "outputId": "0ac9d035-1f16-43e9-99a3-dc76bb4da309"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_projector', 'vocab_transform', 'vocab_layer_norm', 'activation_13']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 84)]         0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 84)]         0           []                               \n",
            "                                                                                                  \n",
            " tf_distil_bert_model_2 (TFDist  TFBaseModelOutput(l  66362880   ['input_ids[0][0]',              \n",
            " ilBertModel)                   ast_hidden_state=(N               'attention_mask[0][0]']         \n",
            "                                one, 84, 768),                                                    \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_2 (Sl  (None, 768)         0           ['tf_distil_bert_model_2[0][0]'] \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " dropout_61 (Dropout)           (None, 768)          0           ['tf.__operators__.getitem_2[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 128)          98432       ['dropout_61[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_62 (Dropout)           (None, 128)          0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)            (None, 128)          0           ['dropout_62[0][0]']             \n",
            "                                                                                                  \n",
            " output (Dense)                 (None, 1)            129         ['flatten_2[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 66,461,441\n",
            "Trainable params: 98,561\n",
            "Non-trainable params: 66,362,880\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
        "def build_model(base_model, trainable=False, params={}):\n",
        "    inputs = Input(shape = (params['max_seq_length'],),name='input_ids', dtype='int32')\n",
        "    masks  = Input(shape = (params['max_seq_length'],),name='attention_mask', dtype='int32')\n",
        "\n",
        "    base_model.trainable = trainable\n",
        "\n",
        "    dbert_output = base_model(inputs, masks)[0]\n",
        "    cls_token = dbert_output[:, 0, :]\n",
        "    dropout_layer = Dropout(params['dropout_rate_1'])(cls_token)\n",
        "    dense_layer = Dense(params['dense_layer_1_units'],activation='relu')(dropout_layer)\n",
        "    dropout_layer = Dropout(params['dropout_rate_2'])(dense_layer)\n",
        "    flatten = Flatten()(dropout_layer)\n",
        "    probs = Dense(1, activation='sigmoid', name=\"output\")(flatten)\n",
        "\n",
        "    model = keras.Model(inputs=[inputs, masks], outputs=probs)\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "MODEL_NAME= 'distilbert-base-uncased'\n",
        "\n",
        "# Configure DistilBERT's initialization\n",
        "config = DistilBertConfig(output_hidden_states=False)\n",
        "                          \n",
        "# The bare, pre-trained DistilBERT transformer model outputting raw hidden-states \n",
        "# and without any specific head on top.\n",
        "dbert_model = TFDistilBertModel.from_pretrained('distilbert-base-uncased', config=config)\n",
        "params={\n",
        "        \"dense_layer_1_units\": 128,        \n",
        "        \"dropout_rate_1\": 0.2,\n",
        "\t      \"dense_layer_2_units\": 32,\n",
        "        \"dropout_rate_2\": 0.2,\n",
        "        \"regularizer_l2_rate\":0.01,\n",
        "        \"max_seq_length\":MAX_VAL\n",
        "        }\n",
        "\n",
        "model = build_model(dbert_model, trainable=False, params=params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "id": "Nh7wo9vgwLSc"
      },
      "outputs": [],
      "source": [
        "def compile_model(model, lr):\n",
        "\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
        "    loss = keras.losses.binary_crossentropy\n",
        "    model.compile(optimizer=optimizer,\n",
        "              loss=loss,\n",
        "              metrics='accuracy')\n",
        "    return model\n",
        "\n",
        "\n",
        "model = compile_model(model, 0.002)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgc2eoalwNk-",
        "outputId": "af80c1f9-494f-4565-88af-02ddd95d505c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "57/57 [==============================] - 22s 386ms/step - loss: 0.4911 - accuracy: 0.7528 - val_loss: 0.3254 - val_accuracy: 0.8617\n",
            "Epoch 2/10\n",
            "57/57 [==============================] - 15s 269ms/step - loss: 0.3425 - accuracy: 0.8522 - val_loss: 0.2706 - val_accuracy: 0.9017\n",
            "Epoch 3/10\n",
            "57/57 [==============================] - 15s 267ms/step - loss: 0.3123 - accuracy: 0.8722 - val_loss: 0.2564 - val_accuracy: 0.8983\n",
            "Epoch 4/10\n",
            "57/57 [==============================] - 15s 266ms/step - loss: 0.3071 - accuracy: 0.8733 - val_loss: 0.2595 - val_accuracy: 0.9017\n",
            "Epoch 5/10\n",
            "57/57 [==============================] - 15s 269ms/step - loss: 0.2909 - accuracy: 0.8767 - val_loss: 0.2520 - val_accuracy: 0.9000\n",
            "Epoch 6/10\n",
            "57/57 [==============================] - 16s 275ms/step - loss: 0.2747 - accuracy: 0.8889 - val_loss: 0.2904 - val_accuracy: 0.8833\n",
            "Epoch 7/10\n",
            "57/57 [==============================] - 15s 268ms/step - loss: 0.2800 - accuracy: 0.8817 - val_loss: 0.2493 - val_accuracy: 0.9083\n",
            "Epoch 8/10\n",
            "57/57 [==============================] - 15s 265ms/step - loss: 0.2732 - accuracy: 0.8906 - val_loss: 0.2441 - val_accuracy: 0.9067\n",
            "Epoch 9/10\n",
            "57/57 [==============================] - 16s 287ms/step - loss: 0.2825 - accuracy: 0.8833 - val_loss: 0.2688 - val_accuracy: 0.8983\n",
            "Epoch 10/10\n",
            "57/57 [==============================] - 15s 264ms/step - loss: 0.2949 - accuracy: 0.8789 - val_loss: 0.2379 - val_accuracy: 0.9117\n"
          ]
        }
      ],
      "source": [
        "def train_model(model, model_inputs_and_masks_train, model_inputs_and_masks_val,\n",
        "    y_train, y_val, batch_size, num_epochs):\n",
        "\n",
        "    dataset_train = tf.data.Dataset.from_tensor_slices((dict(model_inputs_and_masks_train),y_train))\n",
        "    dataset_val = tf.data.Dataset.from_tensor_slices((dict(model_inputs_and_masks_val),y_val))\n",
        "\n",
        "    history = model.fit(dataset_train.shuffle(len(dataset_train)).batch(batch_size), \n",
        "                    epochs=num_epochs, \n",
        "                    batch_size=batch_size,\n",
        "                    validation_data=dataset_val.shuffle(len(dataset_val)).batch(batch_size), \n",
        "                    verbose=1)\n",
        "    \n",
        "    return model, history, dataset_val\n",
        "\n",
        "tf.config.run_functions_eagerly(True) #use function decorator in TF 2.0, please enable run function eagerly by using below line after importing TensorFlow\n",
        "model, history, val_dataset = train_model(model, train_encoding, val_encoding, y_train, y_val, batch_size=32, num_epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOUpymo_wXIo"
      },
      "source": [
        "### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BMRrChy8Ywk",
        "outputId": "5231b8a3-f939-4383-eb58-7eeebab81021"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      1\n",
              "1      1\n",
              "2      1\n",
              "3      1\n",
              "4      1\n",
              "      ..\n",
              "595    0\n",
              "596    0\n",
              "597    0\n",
              "598    0\n",
              "599    0\n",
              "Name: Polarity, Length: 600, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {
        "id": "prMX6HhqwZPO"
      },
      "outputs": [],
      "source": [
        "# Test data - Tensor Conversion\n",
        "def predict_labels(model, dataset):\n",
        "  output = model.predict(dataset.batch(1)) \n",
        "  predicted_labels = (output>0.50)\n",
        "  return output, predicted_labels\n",
        "\n",
        "test_encoding = encode_text(tokenizer, test_df['Sentence_clean'].to_list(), MAX_VAL)\n",
        "dataset_test = tf.data.Dataset.from_tensor_slices((dict(test_encoding)))\n",
        "predicted_prob, predicted_labels = predict_labels(model, dataset_test)\n",
        "#print(\"predicted_prob:\",predicted_prob)\n",
        "#print(\"predicted_labels:\",predicted_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1lYwFFY7lM2",
        "outputId": "304df470-cef8-40cc-cdaf-89641c611561"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.79      0.81       287\n",
            "           1       0.81      0.85      0.83       313\n",
            "\n",
            "    accuracy                           0.82       600\n",
            "   macro avg       0.82      0.82      0.82       600\n",
            "weighted avg       0.82      0.82      0.82       600\n",
            "\n",
            "auc_score_test_nn: 0.9014816711380258\n",
            "accuracy_nn 0.82\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, predicted_labels))\n",
        "fpr, tpr, thresh = roc_curve(y_test, predicted_prob[:], pos_label=1)\n",
        "\n",
        "# roc curve for tpr = fpr \n",
        "random_probs = [0 for i in range(len(y_test))]\n",
        "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)\n",
        "\n",
        "auc_score_nn = roc_auc_score(y_test, predicted_prob[:])\n",
        "\n",
        "print('auc_score_test_nn:',auc_score_nn)\n",
        "print('accuracy_nn %s' % accuracy_score(predicted_labels, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HboWpFGPkyQM"
      },
      "source": [
        "##Deep ML - Conclusion\n",
        "With very basic transfer learning DistilBERT model, our model accuracy raised to 82%. So, its the best model so far."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "MMAI 2022 891 Individual Assignment_Solution.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}