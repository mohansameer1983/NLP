{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MMAI-891-Wysdom-Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohansameer1983/NLP/blob/main/MMAI_891_Wysdom_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZj4c0xTeMwH"
      },
      "source": [
        "# This cell installs and sets up DistilBert import, as well as the dataset, which we will \n",
        "# use tf.datasets to load (https://www.tensorflow.org/datasets/catalog/overview)\n",
        "\n",
        "!pip install -q transformers tfds-nightly\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.cluster import adjusted_rand_score, adjusted_mutual_info_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "try: # this is only working on the 2nd try in colab :)\n",
        "  from transformers import DistilBertTokenizer, TFDistilBertModel, DistilBertConfig, AutoTokenizer, AutoModel, AutoConfig\n",
        "except Exception as err: # so we catch the error and import it again\n",
        "  from transformers import DistilBertTokenizer, TFDistilBertModel, DistilBertConfig, AutoTokenizer, AutoModel, AutoConfig\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout, Flatten\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.metrics.cluster import adjusted_rand_score, adjusted_mutual_info_score\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import re"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google drive so dataset can be accessed\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ymezdl5J0Lz",
        "outputId": "abde6597-801e-4cfe-f438-60fc9ba05824"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "jHvJJjnCRYF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "  data_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/data/public_data.csv\")\n",
        "  return data_df\n",
        "\n",
        "orig_data = load_data()\n",
        "orig_data"
      ],
      "metadata": {
        "id": "q3gYLKfEd0Hb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "9d74900d-1809-4628-bd43-fc7c002433f6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id                                            message  \\\n",
              "0     10480                           start the robotic vacuum   \n",
              "1      4210          i am sorry but i think you are not right.   \n",
              "2      2443  what is the time difference between california...   \n",
              "3      5869                              tell me my list names   \n",
              "4      2801                 beep when i get an email from john   \n",
              "...     ...                                                ...   \n",
              "8879   9708             search for a train ticket to newcastle   \n",
              "8880   8278               is there a food festival in the area   \n",
              "8881  10509                       make the lights blue in here   \n",
              "8882   7046                           play from favorites song   \n",
              "8883    248                                send a replay email   \n",
              "\n",
              "                      label  \n",
              "0              iot_cleaning  \n",
              "1            general_negate  \n",
              "2          datetime_convert  \n",
              "3               lists_query  \n",
              "4               email_query  \n",
              "...                     ...  \n",
              "8879       transport_ticket  \n",
              "8880  recommendation_events  \n",
              "8881    iot_hue_lightchange  \n",
              "8882             play_music  \n",
              "8883        email_sendemail  \n",
              "\n",
              "[8884 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b26eaf0e-b7ff-413a-9c34-2b70e8c78c00\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>message</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10480</td>\n",
              "      <td>start the robotic vacuum</td>\n",
              "      <td>iot_cleaning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4210</td>\n",
              "      <td>i am sorry but i think you are not right.</td>\n",
              "      <td>general_negate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2443</td>\n",
              "      <td>what is the time difference between california...</td>\n",
              "      <td>datetime_convert</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5869</td>\n",
              "      <td>tell me my list names</td>\n",
              "      <td>lists_query</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2801</td>\n",
              "      <td>beep when i get an email from john</td>\n",
              "      <td>email_query</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8879</th>\n",
              "      <td>9708</td>\n",
              "      <td>search for a train ticket to newcastle</td>\n",
              "      <td>transport_ticket</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8880</th>\n",
              "      <td>8278</td>\n",
              "      <td>is there a food festival in the area</td>\n",
              "      <td>recommendation_events</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8881</th>\n",
              "      <td>10509</td>\n",
              "      <td>make the lights blue in here</td>\n",
              "      <td>iot_hue_lightchange</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8882</th>\n",
              "      <td>7046</td>\n",
              "      <td>play from favorites song</td>\n",
              "      <td>play_music</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8883</th>\n",
              "      <td>248</td>\n",
              "      <td>send a replay email</td>\n",
              "      <td>email_sendemail</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8884 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b26eaf0e-b7ff-413a-9c34-2b70e8c78c00')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b26eaf0e-b7ff-413a-9c34-2b70e8c78c00 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b26eaf0e-b7ff-413a-9c34-2b70e8c78c00');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "orig_data.drop_duplicates(inplace= True)"
      ],
      "metadata": {
        "id": "gX982idqTINz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orig_data.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW9TNeaAToOS",
        "outputId": "e3caa8e9-9b57-4ba2-95da-c211df38fca2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id         0\n",
              "message    0\n",
              "label      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = []\n",
        "for row in orig_data['message']:\n",
        "    max_words.append(len(row.split()))\n",
        "print(f\"The max word count is {np.asarray(max_words).max()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6SZBEMHT1Qj",
        "outputId": "bda1b533-3489-48c2-ae47-3e82f3ad4da3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The max word count is 25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Split Data\n",
        "\n",
        "## Training Data Split"
      ],
      "metadata": {
        "id": "hCPAiqgANblk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_and_y(df, test_size):\n",
        "\n",
        "  text = df['message']\n",
        "\n",
        "  le = LabelEncoder()\n",
        "  df['label_encoded'] = le.fit_transform(df['label'])\n",
        "  y = df['label_encoded']\n",
        "\n",
        "  label_dict = (df[['label','label_encoded']].drop_duplicates()\n",
        "              .sort_values(by='label_encoded')\n",
        "              .reset_index(drop=True)['label']\n",
        "              .to_dict())\n",
        "  \n",
        "\n",
        "\n",
        "  X_train, X_val, y_train, y_val = train_test_split(text, y, test_size=test_size, random_state=2)\n",
        "  return X_train, X_val, y_train, y_val, label_dict\n",
        "\n",
        "# the following prepares the input for running in DistilBert\n",
        "train_text, val_text, train_y, val_y, label_dict = extract_text_and_y(orig_data, 0.20)"
      ],
      "metadata": {
        "id": "_RBthPA0fcTA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrP1hRswIaEI",
        "outputId": "bd0f6c75-99f7-4f0a-868c-b07cf1ada43c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8011    save the information which is provided by aman...\n",
              "2612                       please raise the lights to max\n",
              "8642                            the song touches my heart\n",
              "3724                         yeap you get that perfectly.\n",
              "4753                                     mute immediately\n",
              "                              ...                        \n",
              "1099                                         play my game\n",
              "2514                                     back one episode\n",
              "6637         i can't hear you can you say it again louder\n",
              "2575    tell me about current status of sunderland vs ...\n",
              "7336                                make this my favorite\n",
              "Name: message, Length: 7107, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2sXHjYKIdBF",
        "outputId": "e4d1a05d-d79d-48f1-a91e-d66a854fb776"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8011    38\n",
              "2612    32\n",
              "8642    38\n",
              "3724    16\n",
              "4753     4\n",
              "        ..\n",
              "1099    43\n",
              "2514    45\n",
              "6637     5\n",
              "2575    41\n",
              "7336    38\n",
              "Name: label_encoded, Length: 7107, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tc2JZ8sxG-hu",
        "outputId": "fbdbfcbc-dda6-475e-8c86-47911ac0b54c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'alarm_query',\n",
              " 1: 'alarm_remove',\n",
              " 2: 'alarm_set',\n",
              " 3: 'audio_volume_down',\n",
              " 4: 'audio_volume_mute',\n",
              " 5: 'audio_volume_up',\n",
              " 6: 'calendar_query',\n",
              " 7: 'calendar_remove',\n",
              " 8: 'calendar_set',\n",
              " 9: 'cooking_recipe',\n",
              " 10: 'datetime_convert',\n",
              " 11: 'datetime_query',\n",
              " 12: 'email_addcontact',\n",
              " 13: 'email_query',\n",
              " 14: 'email_querycontact',\n",
              " 15: 'email_sendemail',\n",
              " 16: 'general_affirm',\n",
              " 17: 'general_commandstop',\n",
              " 18: 'general_confirm',\n",
              " 19: 'general_dontcare',\n",
              " 20: 'general_explain',\n",
              " 21: 'general_joke',\n",
              " 22: 'general_negate',\n",
              " 23: 'general_praise',\n",
              " 24: 'general_quirky',\n",
              " 25: 'general_repeat',\n",
              " 26: 'iot_cleaning',\n",
              " 27: 'iot_coffee',\n",
              " 28: 'iot_hue_lightchange',\n",
              " 29: 'iot_hue_lightdim',\n",
              " 30: 'iot_hue_lightoff',\n",
              " 31: 'iot_hue_lighton',\n",
              " 32: 'iot_hue_lightup',\n",
              " 33: 'iot_wemo_off',\n",
              " 34: 'iot_wemo_on',\n",
              " 35: 'lists_createoradd',\n",
              " 36: 'lists_query',\n",
              " 37: 'lists_remove',\n",
              " 38: 'music_likeness',\n",
              " 39: 'music_query',\n",
              " 40: 'music_settings',\n",
              " 41: 'news_query',\n",
              " 42: 'play_audiobook',\n",
              " 43: 'play_game',\n",
              " 44: 'play_music',\n",
              " 45: 'play_podcasts',\n",
              " 46: 'play_radio',\n",
              " 47: 'qa_currency',\n",
              " 48: 'qa_definition',\n",
              " 49: 'qa_factoid',\n",
              " 50: 'qa_maths',\n",
              " 51: 'qa_stock',\n",
              " 52: 'recommendation_events',\n",
              " 53: 'recommendation_locations',\n",
              " 54: 'recommendation_movies',\n",
              " 55: 'social_post',\n",
              " 56: 'social_query',\n",
              " 57: 'takeaway_order',\n",
              " 58: 'takeaway_query',\n",
              " 59: 'transport_query',\n",
              " 60: 'transport_taxi',\n",
              " 61: 'transport_ticket',\n",
              " 62: 'transport_traffic',\n",
              " 63: 'weather_query'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize Data"
      ],
      "metadata": {
        "id": "mXYXnSLUQPnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get length of all the messages in the train set\n",
        "seq_len = [len(i.split()) for i in train_text]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "BEYh7BgKP31K",
        "outputId": "eb579494-72b8-45e0-a958-c782f81144d6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa3ed461fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Embeddings using DistilBERT "
      ],
      "metadata": {
        "id": "M5mSR4zZQXIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get DistilBERT Tokenizer\n",
        "#tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased', add_prefix_space=True, use_fast=False)"
      ],
      "metadata": {
        "id": "6KFNaMH3ZrsR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check longest token sequence in entire text\n",
        "def checkForMaxTokenSeqInData(text_list, tokenizer_i):\n",
        "  \n",
        "    max_val = 0\n",
        "    for sent in text_list:\n",
        "        try:\n",
        "            sent_tok_len = len(tokenizer_i.tokenize(sent))\n",
        "            max_val = sent_tok_len if (sent_tok_len > max_val) else max_val\n",
        "        except:\n",
        "            pass\n",
        "    \n",
        "    print(f\"The maximum amount of tokens in the dataset is {max_val}\")\n",
        "    return max_val\n",
        "\n",
        "MAX_VAL = checkForMaxTokenSeqInData(train_text.tolist()+val_text.tolist(),tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1IxB3GKaedr",
        "outputId": "181593ff-7ad1-4b7e-c20f-920c5ef5956d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The maximum amount of tokens in the dataset is 28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_text(tokenizer_i, text, max_text_length):\n",
        "\n",
        "    # Encode the sentence\n",
        "    encodedText = tokenizer_i.batch_encode_plus(\n",
        "        text,  # the sentence to be encoded\n",
        "        add_special_tokens=True,  # Add [CLS] and [SEP]\n",
        "        max_length = max_text_length,\n",
        "        padding='max_length',\n",
        "        truncation=True\n",
        "        )\n",
        "    # Get the input IDs and attention mask in tensor format\n",
        "    input_ids = tf.convert_to_tensor(encodedText['input_ids'])\n",
        "    attention_mask = tf.convert_to_tensor(encodedText['attention_mask'])\n",
        "    print(input_ids[0])\n",
        "    print(tokenizer.convert_ids_to_tokens(input_ids[0]))\n",
        "    return input_ids, attention_mask\n",
        "\n",
        "train_input, train_mask = encode_text(tokenizer, train_text, MAX_VAL)\n",
        "val_input, val_mask = encode_text(tokenizer, val_text, MAX_VAL)\n",
        "\n",
        "train_model_inputs_and_masks = {\n",
        "    'inputs' : train_input,\n",
        "    'masks' : train_mask\n",
        "}\n",
        "\n",
        "val_model_inputs_and_masks = {\n",
        "    'inputs' : val_input,\n",
        "    'masks' : val_mask\n",
        "}"
      ],
      "metadata": {
        "id": "yr39D9u1QBhX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59437497-bb95-4935-d71d-0c9c9ffabc9e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[  101  3828  1996  2592  2029  2003  3024  2011 25933  2078  2006  2023\n",
            "  2299   102     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0], shape=(28,), dtype=int32)\n",
            "['[CLS]', 'save', 'the', 'information', 'which', 'is', 'provided', 'by', 'ama', '##n', 'on', 'this', 'song', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
            "tf.Tensor(\n",
            "[  101  2131  2033  1996  2334  3345 10984  2000  7688 20116 21246   102\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0], shape=(28,), dtype=int32)\n",
            "['[CLS]', 'get', 'me', 'the', 'local', 'train', 'timing', 'to', 'destination', 'cs', '##tm', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2USajN2MWjn"
      },
      "source": [
        "# Modelling\n",
        "\n",
        "## Build and Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZfFboF85rIe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "876ab3ba-43cb-4f9e-e170-3031260a382d"
      },
      "source": [
        "def build_model(base_model, trainable=False, params={}):\n",
        "    inputs = Input(shape = (params['max_seq_length'],),name='input_ids', dtype='int32')\n",
        "    masks  = Input(shape = (params['max_seq_length'],),name='input_attention', dtype='int32')\n",
        "\n",
        "    base_model.trainable = trainable\n",
        "\n",
        "    dbert_output = base_model([inputs, masks])[0]\n",
        "    dense_layer = Dense(params['dense_layer_1_units'],activation='relu')(dbert_output)\n",
        "    dropout_layer = Dropout(params['dropout_rate_1'])(dense_layer)\n",
        "    dense_layer = Dense(params['dense_layer_2_units'],activation='relu')(dropout_layer)\n",
        "    dropout_layer = Dropout(params['dropout_rate_2'])(dense_layer)\n",
        "    flatten = Flatten()(dense_layer)\n",
        "    probs = Dense(len(label_dict), activation='softmax', name=\"output\")(flatten)\n",
        "\n",
        "    model = keras.Model(inputs=[inputs, masks], outputs=probs)\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "MODEL_NAME= 'distilbert-base-uncased'\n",
        "\n",
        "# Configure DistilBERT's initialization\n",
        "config = DistilBertConfig(output_hidden_states=True)\n",
        "                          \n",
        "# The bare, pre-trained DistilBERT transformer model outputting raw hidden-states \n",
        "# and without any specific head on top.\n",
        "dbert_model = TFDistilBertModel.from_pretrained('distilbert-base-uncased', config=config)\n",
        "\n",
        "params={\n",
        "        \"dense_layer_1_units\": 128,        \n",
        "        \"dropout_rate_1\": 0.2,\n",
        "\t      \"dense_layer_2_units\": 32,\n",
        "        \"dropout_rate_2\": 0.2,\n",
        "        \"regularizer_l2_rate\":0.01,\n",
        "        \"max_seq_length\":MAX_VAL\n",
        "        }\n",
        "\n",
        "model = build_model(dbert_model, params=params)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_transform', 'activation_13', 'vocab_projector', 'vocab_layer_norm']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 28)]         0           []                               \n",
            "                                                                                                  \n",
            " input_attention (InputLayer)   [(None, 28)]         0           []                               \n",
            "                                                                                                  \n",
            " tf_distil_bert_model_1 (TFDist  TFBaseModelOutput(l  66362880   ['input_ids[0][0]',              \n",
            " ilBertModel)                   ast_hidden_state=(N               'input_attention[0][0]']        \n",
            "                                one, 28, 768),                                                    \n",
            "                                 hidden_states=((No                                               \n",
            "                                ne, 28, 768),                                                     \n",
            "                                 (None, 28, 768),                                                 \n",
            "                                 (None, 28, 768),                                                 \n",
            "                                 (None, 28, 768),                                                 \n",
            "                                 (None, 28, 768),                                                 \n",
            "                                 (None, 28, 768),                                                 \n",
            "                                 (None, 28, 768)),                                                \n",
            "                                 attentions=None)                                                 \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 28, 128)      98432       ['tf_distil_bert_model_1[0][7]'] \n",
            "                                                                                                  \n",
            " dropout_40 (Dropout)           (None, 28, 128)      0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 28, 32)       4128        ['dropout_40[0][0]']             \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 896)          0           ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " output (Dense)                 (None, 64)           57408       ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 66,522,848\n",
            "Trainable params: 159,968\n",
            "Non-trainable params: 66,362,880\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compile_model(model, lr):\n",
        "\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
        "    loss = keras.losses.sparse_categorical_crossentropy\n",
        "    model.compile(optimizer=optimizer,\n",
        "              loss=loss,\n",
        "              metrics='accuracy')\n",
        "    return model\n",
        "\n",
        "\n",
        "model = compile_model(model, 0.003)"
      ],
      "metadata": {
        "id": "Z3EyvQbSzu5m"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add Callbacks\n",
        "\n",
        "# Model Checkpoint\n",
        "tl_checkpoint_1 = ModelCheckpoint(filepath = '/content/drive/MyDrive/Colab Notebooks/Models/NLP/distilBert_text_classification_model_weights.hdf5', save_best_only = True, save_weights_only=True, verbose = 0)\n",
        "\n",
        "# Early Stopping Checkpoint\n",
        "EarlyStoppingCallback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10)"
      ],
      "metadata": {
        "id": "QMV6fxol6Qlo"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, model_inputs_and_masks_train, model_inputs_and_masks_val,\n",
        "    y_train, y_val, batch_size, num_epochs):\n",
        "\n",
        "    # Training Data - Tensor Conversion\n",
        "    input_ids_train = model_inputs_and_masks_train['inputs']\n",
        "    attention_masks_train = model_inputs_and_masks_train['masks']\n",
        "    labels_train = tf.convert_to_tensor(y_train[:])\n",
        "\n",
        "    # Validation data - Tensor Conversion\n",
        "    input_ids_val = model_inputs_and_masks_val['inputs']\n",
        "    attention_masks_val = model_inputs_and_masks_val['masks']\n",
        "    labels_val = tf.convert_to_tensor(y_val[:])\n",
        "\n",
        "    # Preparing Training Dataset\n",
        "    dataset_train = tf.data.Dataset.from_tensors(( (input_ids_train, attention_masks_train), labels_train ))\n",
        "    dataset_val = tf.data.Dataset.from_tensors(( (input_ids_val, attention_masks_val), labels_val ))\n",
        "\n",
        "    history = model.fit(dataset_train,\n",
        "          epochs=num_epochs,\n",
        "          validation_data=dataset_val,\n",
        "          batch_size=batch_size, verbose=1,\n",
        "          callbacks=[tl_checkpoint_1,EarlyStoppingCallback])\n",
        "    \n",
        "    return model, history\n",
        "\n",
        "model, history = train_model(model, train_model_inputs_and_masks, val_model_inputs_and_masks, train_y, val_y, batch_size=32, num_epochs=100)"
      ],
      "metadata": {
        "id": "Nz8kT3f8zykl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05059e19-a60b-443b-89ec-1562fc10e4ff"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 7s 7s/step - loss: 0.2187 - accuracy: 0.9311 - val_loss: 0.5551 - val_accuracy: 0.8497\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2091 - accuracy: 0.9365 - val_loss: 0.5547 - val_accuracy: 0.8464\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1897 - accuracy: 0.9446 - val_loss: 0.5626 - val_accuracy: 0.8475\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1942 - accuracy: 0.9403 - val_loss: 0.5559 - val_accuracy: 0.8486\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1912 - accuracy: 0.9415 - val_loss: 0.5561 - val_accuracy: 0.8526\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1874 - accuracy: 0.9437 - val_loss: 0.5550 - val_accuracy: 0.8548\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1857 - accuracy: 0.9444 - val_loss: 0.5592 - val_accuracy: 0.8497\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1766 - accuracy: 0.9460 - val_loss: 0.5655 - val_accuracy: 0.8492\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1694 - accuracy: 0.9506 - val_loss: 0.5642 - val_accuracy: 0.8492\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1593 - accuracy: 0.9544 - val_loss: 0.5607 - val_accuracy: 0.8514\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1663 - accuracy: 0.9510 - val_loss: 0.5589 - val_accuracy: 0.8554\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1523 - accuracy: 0.9565 - val_loss: 0.5621 - val_accuracy: 0.8548\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1553 - accuracy: 0.9544 - val_loss: 0.5616 - val_accuracy: 0.8514\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1473 - accuracy: 0.9589 - val_loss: 0.5657 - val_accuracy: 0.8554\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1414 - accuracy: 0.9588 - val_loss: 0.5656 - val_accuracy: 0.8514\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1429 - accuracy: 0.9598 - val_loss: 0.5627 - val_accuracy: 0.8559\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1387 - accuracy: 0.9588 - val_loss: 0.5650 - val_accuracy: 0.8582\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1318 - accuracy: 0.9621 - val_loss: 0.5639 - val_accuracy: 0.8582\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1347 - accuracy: 0.9600 - val_loss: 0.5638 - val_accuracy: 0.8526\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1250 - accuracy: 0.9650 - val_loss: 0.5620 - val_accuracy: 0.8526\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1248 - accuracy: 0.9648 - val_loss: 0.5668 - val_accuracy: 0.8537\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1208 - accuracy: 0.9679 - val_loss: 0.5754 - val_accuracy: 0.8588\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1172 - accuracy: 0.9674 - val_loss: 0.5773 - val_accuracy: 0.8593\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1181 - accuracy: 0.9664 - val_loss: 0.5676 - val_accuracy: 0.8582\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1083 - accuracy: 0.9705 - val_loss: 0.5620 - val_accuracy: 0.8565\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1075 - accuracy: 0.9719 - val_loss: 0.5651 - val_accuracy: 0.8571\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1031 - accuracy: 0.9700 - val_loss: 0.5727 - val_accuracy: 0.8565\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1030 - accuracy: 0.9719 - val_loss: 0.5788 - val_accuracy: 0.8571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict & Calculate Score"
      ],
      "metadata": {
        "id": "7w_va2o93psm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation data - Tensor Conversion\n",
        "def predict_labels(model, model_inputs_and_masks_val, y_vals):\n",
        "  input_ids_val = model_inputs_and_masks_val['inputs']\n",
        "  attention_masks_val = model_inputs_and_masks_val['masks']\n",
        "  labels_val = tf.convert_to_tensor(y_vals[:])\n",
        "  dataset_val = tf.data.Dataset.from_tensors(( (input_ids_val, attention_masks_val), labels_val ))\n",
        "  output_val = model.predict(dataset_val)\n",
        "  predicted_labels = np.argmax(output_val, axis=1)\n",
        "  return predicted_labels\n",
        "\n",
        "predicted_labels = predict_labels(model, val_model_inputs_and_masks,val_y)\n",
        "predicted_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgS6IMMT2SE_",
        "outputId": "cddb668a-590b-409f-876b-21d4f7c2baeb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([59, 58,  6, ..., 12, 57, 51])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Scores\n",
        "def calculate_score(val_y, predicted_labels):\n",
        "  ari_val = adjusted_rand_score(val_y, predicted_labels)\n",
        "  ami_val = adjusted_mutual_info_score(val_y, predicted_labels, average_method='arithmetic')\n",
        "  print(\"ari_val:\", ari_val)\n",
        "  print(\"ami_val:\", ami_val)\n",
        "  return\n",
        "\n",
        "calculate_score(val_y, predicted_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AD64E5TH46nr",
        "outputId": "50a111ad-b2be-4901-9db9-f0b1a0bf4577"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ari_val: 0.7445293697674149\n",
            "ami_val: 0.8256530220334212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fine Tuning Custom DistilBERT Model"
      ],
      "metadata": {
        "id": "z2vZXKsxNway"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze distilBERT layers and make available for training\n",
        "def fine_tune_transfer_learning_model(base_transfomer_model, custom_model, learning_rate):\n",
        "\n",
        "    base_transfomer_model.trainable = True\n",
        "    \n",
        "    # Recompile model after unfreezing\n",
        "    model_updated = compile_model(custom_model, learning_rate)\n",
        "    custom_model.summary()\n",
        "    \n",
        "    model_updated, history2 = train_model(model_updated, train_model_inputs_and_masks, val_model_inputs_and_masks, train_y, val_y, batch_size=16, num_epochs=5)\n",
        "\n",
        "    return custom_model, history2\n",
        "\n",
        "model2, history2=fine_tune_transfer_learning_model(dbert_model, model, 1e-5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODpQjmwAOHzs",
        "outputId": "8a0ab281-a60d-48b6-ef57-93bd956982c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 28)]         0           []                               \n",
            "                                                                                                  \n",
            " input_attention (InputLayer)   [(None, 28)]         0           []                               \n",
            "                                                                                                  \n",
            " tf_distil_bert_model_1 (TFDist  TFBaseModelOutput(l  66362880   ['input_ids[0][0]',              \n",
            " ilBertModel)                   ast_hidden_state=(N               'input_attention[0][0]']        \n",
            "                                one, 28, 768),                                                    \n",
            "                                 hidden_states=((No                                               \n",
            "                                ne, 28, 768),                                                     \n",
            "                                 (None, 28, 768),                                                 \n",
            "                                 (None, 28, 768),                                                 \n",
            "                                 (None, 28, 768),                                                 \n",
            "                                 (None, 28, 768),                                                 \n",
            "                                 (None, 28, 768),                                                 \n",
            "                                 (None, 28, 768)),                                                \n",
            "                                 attentions=None)                                                 \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 28, 128)      98432       ['tf_distil_bert_model_1[0][7]'] \n",
            "                                                                                                  \n",
            " dropout_40 (Dropout)           (None, 28, 128)      0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 28, 32)       4128        ['dropout_40[0][0]']             \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 896)          0           ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " output (Dense)                 (None, 64)           57408       ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 66,522,848\n",
            "Trainable params: 66,522,848\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n"
          ]
        }
      ]
    }
  ]
}